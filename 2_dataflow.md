# Что такое Dataflow

Это когда _данные управляют выполнением_. Такие программы реагируют, обновляясь, на данные, когда они приходят.

## Pipeline Dataflow

Простейшая реализация Dataflow. 

## Узлы (nodes)

Вычислительный элемент со вводом и выводом, осуществляющий какую-то операцию. Единственный способ узлу получить и отправить данные это через "порты".

Pipeline dataflow позволяет один входной и один выходной порты. Когда у узлов несколько портов, они чаще всего имеют имена.

Узлы чаще всего _идемпотентны_, но это не не обязательно. Исполнение кода узлом называется _активацией_ или "firing".

## Данные

Удивительно для методологии со словом "Data" в имени, dataflow не взаимодействует со значениями данных напрямую. Данные в dataflow представлены в виде "токенов" (представление данных независимо от их структуры).

Изменяемость (mutability) данных играет важную роль, т.к. аффектит параллелизм, однако, она напрямую не запрещена в dataflow. Pipeline dataflow обычно использует неизменяемость данных.

## Дуги (arcs)

Путь, который проделывает _токен_ от одного узла к другому называется _дугой_. Для упрощения будем думать, что данные движутся всегда от выходных портов к входным. Другие имена для дуги это _ребро, провод, соединение_ или _ссылка_.

О дуге можно думать как о трубе, которая один или более токенов. Обязательное условие для активации узла - как минимум один токен ждёт на входе и выходная дуга свободна. Вычитывание данных со входного порта освобождает дугу для ввода новых данных. _Вместимость дуги_ - кол-во токенов, которые она может вмещать в один момент времени.

Соединение и разделение дуг запрещено в pipeline dataflow, однако, разрешено в других ветвях dataflow и будет рассмотренно позже.

## Dataflow графы

Направленный граф содержащий узлы (вершины) и дуги (рёбра) между ними. Все соединения явно объявлены программистом. Граф также называется dataflow программой. 

## Выполнение графа

В pipeline dataflow (и большинстве остальных dataflow направлений) узлы активированы только тогда, когда на входе есть данные. _Data-driven execution_ - появление данных вызывает активность узлов и их отсутствие, позволяет им уходить в _режим ожидания_ (idle). Узлы могут работать одновременно при условии постоянного потока данных.

Узел, получив данные на входе, не обязан отправлять данные на выход. Логика может быть какой угодно. От этого зависит активация _последующего_ (downstream) узла.

## Возможности dataflow систем

Pipeline dataflow очень проста в реализации, но, тем не менее, полезна. Однако, она накладывает ограничения на то, какие программы можно реализовать с её помощью.

Unix pipes, цепочка ответственности, stream processors 
и фильтры - всё это pipeline dataflow. Это настолько очевидное решение, что оно переизобреталось множество раз. Посмотрим, как можно расширить pipeline dataflow, чтобы сделать его мощнее. Некоторые такие комбинации дают нам Synchronous Dataflow и Flow-Based Programming.

Некоторые возможности лучше не совмещать. Например, изменяемость данных и разделение дуг - придётся делать глупокое копирование для каждого получателя.

## Push vs Pull data

Определяет то, как токены движутся по системе. 

Push - узлы шлют данные другим узлам всякий раз, когда можно. Поставщик данных управляет движением. Браузер, посылающий запросы серверу, это пример _push data_. 

Pull - получатель управляет движением. Один узел запрашивает данные у второго, тот у третьего и так далее по цепочке до тех пор, пока не находится узел, который не запрашивает данные ни у кого. 

Pull подход редко используется в dataflow системах, однако, полезен, когда вычисление, которое делает узел, дорого - pull позволяет его _отложить_ (lazy) до тех пор, пока оно кому-то не понадобится.

## Изменяемые и неизменяемые данные

Рассмотрим пример: один и тот же токен отправлен в 2 узла и был изменён в одном из них. В случае мутабельных данных, узел 2 получает изменённую версию и, если тоже изменяет данные, то данные из узла 1 потеряны. Изменяемость данных усложняет ключевую фишку dataflow - возможности параллельного исполнения множества узлов без необходимости думать о блокировках. Неизменяемость предпочтительна всегда, когда речь идет о параллелизме. Как уже было сказано, появляется необходимость (глубокого) копирования данных (которые отображает токен) при наличии split функции.

Копирование токена неизбежно при наличии мутаций. Мутации неизбежны при _интеропе_  с императивными языками.

## Static vs Dynamic

### Dynamic

Позволяет динамически изменять граф или переопределять узлы в _рантайме_. Похоже на механизм HOF в "обычных" языках.

Подмена узла (_Node replacement_) - замена узла другим во время выполнения.  Подмена дуги (_Arcs modifying_) - другой подход, изменений структуры графа в рантайме. Звучит круто, но по факту ведёт усложнению дебага. 

Замена узла безопаснее чем дуги, но также должна использоваться в случае реальной необходимости. Например, уменьшить кол-во шаблонного кода, когда его реально много. Оба - замена узла и замена дуги - ведут к усложнению дебага.

### Static

Никакие изменения не могут быть сделаны в рантайме. Граф (узлы и дуги) - зафиксированы. Это похоже на то, как нельзя изменить (статичную) структуру в языках вроде C.

Статичные dataflow программы могут, заметим, использовать сколько угодно копий одного и того же узла. Обратное ограничение относится к dataflow железу, но не софту.

Статичный dataflow похож на реальную электронную схему - нельзя просто так "из воздуха" создать новый узел. Структура схемы известна заранее и неизменяема.